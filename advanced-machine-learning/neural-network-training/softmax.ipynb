{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b113b42",
   "metadata": {},
   "source": [
    "## Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from my_samples_generator import make_blobs\n",
    "from lab_utils_softmax import plt_softmax\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Allows us to manage and control the log messages\n",
    "import logging\n",
    "# Sets the logging level for tensorflow to show only errors\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# Controls the verbosity of tensorflow autograph i.e; python code to tensorflow graph code\n",
    "tf.autograph.set_verbosity(0)\n",
    "# Disables internal logging or output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "  e_z=np.exp(z)\n",
    "  sm=e_z/np.sum(e_z)\n",
    "  return (sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd50073",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_softmax(my_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers=[[-5, 2], [-2, -2], [1, 2], [5, -2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640159c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train=make_blobs(n_samples=2000, centers=centers, cluster_std=1.0, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c91ec3",
   "metadata": {},
   "source": [
    "### Traditional model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866aa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential(\n",
    "  [\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=4, activation='softmax')\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ee592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss=SparseCategoricalCrossentropy(),\n",
    "  optimizer=Adam(learning_rate=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b375a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  x_train, y_train,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_traditional=model.predict(x_train)\n",
    "print(softmax_traditional[:2])\n",
    "print(np.max(softmax_traditional), np.min(softmax_traditional))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a61e72",
   "metadata": {},
   "source": [
    "### Preferred model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5284018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential(\n",
    "  [\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=4, activation='linear')\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=Adam(learning_rate=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  x_train, y_train,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_preferred=model.predict(x_train) # the outputs are not probabilities\n",
    "\n",
    "softmax_preferred_prob=tf.nn.softmax(softmax_preferred).numpy()\n",
    "print(softmax_preferred_prob[:2])\n",
    "print(np.max(softmax_preferred_prob), np.min(softmax_preferred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ac7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  print(f\"{softmax_preferred[i]}, category: {np.argmax(softmax_preferred[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614b90d",
   "metadata": {},
   "source": [
    "Tensorflow has two potential formats for target values and the selection of the loss defines which is expected.\n",
    "- SparseCategorialCrossentropy: expects the target to be an integer corresponding to the index. For example, if there are 10 potential target values, y would be between 0 and 9. \n",
    "- CategoricalCrossEntropy: Expects the target value of an example to be one-hot encoded where the value at the target index is 1 while the other N-1 entries are zero. An example with 10 potential target values, where the target is 2 would be [0,0,1,0,0,0,0,0,0,0]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
