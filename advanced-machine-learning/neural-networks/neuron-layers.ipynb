{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b176afb2",
   "metadata": {},
   "source": [
    "## Neurons and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input # type: ignore\n",
    "from tensorflow.keras import Sequential # type: ignore\n",
    "from lab_utils_common import dlc\n",
    "from lab_neurons_utils import sigmoidnp, plt_linear, plt_logistic\n",
    "\n",
    "# Allows us to manage and control the log messages\n",
    "import logging\n",
    "# Sets the logging level for tensorflow to show only errors\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# Controls the verbosity of tensorflow autograph i.e; python code to tensorflow graph code\n",
    "tf.autograph.set_verbosity(0)\n",
    "# Disables internal logging or output messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57260da",
   "metadata": {},
   "source": [
    "### Neuron without activation - Regression/Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5497f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array([[1.0], [2.0]], dtype=np.float32)\n",
    "y_train=np.array([[300.0], [500.0]], dtype=np.float32)\n",
    "\n",
    "fig, ax=plt.subplots(1, 1)\n",
    "ax.scatter(x_train, y_train, marker='x', c='r', label=\"Data points\")\n",
    "ax.legend(fontsize=\"xx-large\")\n",
    "ax.set_xlabel('Size (1000 sqft)', fontsize=\"xx-large\")\n",
    "ax.set_ylabel('Price (1000 dollars)', fontsize=\"xx-large\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17039ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer=Dense(units=1, activation='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789363b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e277346",
   "metadata": {},
   "source": [
    "There are no weights as the weights are not yet instantiated. Let's try the model on one example in `X_train`. This will trigger the instantiation of the weights. Note, the input to the layer must be 2-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=linear_layer(x_train[0].reshape(1, 1))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b=linear_layer.get_weights()\n",
    "print(f\"w={w}, b={b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w=np.array([[200]])\n",
    "set_b=np.array([100])\n",
    "\n",
    "linear_layer.set_weights([set_w, set_b])\n",
    "print(linear_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=linear_layer(x_train[0].reshape(1, 1))\n",
    "print(a1)\n",
    "a_lin=np.dot(set_w, x_train[0].reshape(1, 1))+set_b\n",
    "print(a_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tf=linear_layer(x_train)\n",
    "pred_np=np.dot(x_train, set_w)+set_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_linear(x_train, y_train, pred_tf, pred_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765748e",
   "metadata": {},
   "source": [
    "### Neuron with sigmoid activation - Logistic neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array([0, 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1, 1)\n",
    "y_train=np.array([0, 0, 0, 1, 1, 1], dtype=np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023dddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=y_train==1\n",
    "neg=y_train==0\n",
    "\n",
    "print(x_train[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1, 1, figsize=(4, 3))\n",
    "ax.scatter(x_train[pos], y_train[pos], marker='x', s=80, c='red', label='y=1')\n",
    "ax.scatter(x_train[neg], y_train[neg], marker='o', s=100, label='y=0', \n",
    "           facecolors='none', edgecolors=dlc['dlblue'], lw=3)\n",
    "\n",
    "ax.set_ylim([-0.08, 1.1])\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('Y', fontsize=12)\n",
    "ax.set_title('One variable plot')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bf23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential(\n",
    "  [\n",
    "    Input(shape=(1,)),\n",
    "    Dense(units=1, activation='sigmoid', name=\"L1\")\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b37269",
   "metadata": {},
   "source": [
    "`model.summary()` shows the layers and number of parameters in the model. There is only one layer in this model and that layer has only one unit. The unit has two parameters, $w$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be646e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfa5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_layer=model.get_layer(\"L1\")\n",
    "w, b=logistic_layer.get_weights()\n",
    "print(w, b, w.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e767bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w=np.array([[2]])\n",
    "set_b=np.array([-4.5])\n",
    "\n",
    "logistic_layer.set_weights([set_w, set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caeb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=model.predict(x_train[0].reshape(1, 1))\n",
    "print(a1)\n",
    "a_log=sigmoidnp(np.dot(set_w, x_train[0].reshape(1, 1))+set_b)\n",
    "print(a_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36897194",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_logistic(x_train, y_train, model, set_w, set_b, pos, neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
